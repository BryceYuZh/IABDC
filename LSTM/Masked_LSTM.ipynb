{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setting seed for reproducability\n",
    "np.random.seed(1234)  \n",
    "PYTHONHASHSEED = 0\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation, Conv1D, MaxPooling1D, Masking\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n0   1      1   34.9983    0.8400     100.0  449.44  555.32  1358.61  1137.23   \n1   1      2   41.9982    0.8408     100.0  445.00  549.90  1353.22  1125.78   \n2   1      3   24.9988    0.6218      60.0  462.54  537.31  1256.76  1047.45   \n3   1      4   42.0077    0.8416     100.0  445.00  549.51  1354.03  1126.38   \n4   1      5   25.0005    0.6203      60.0  462.54  537.07  1257.71  1047.93   \n\n     s5  ...     s12      s13      s14      s15   s16  s17   s18     s19  \\\n0  5.48  ...  183.06  2387.72  8048.56   9.3461  0.02  334  2223  100.00   \n1  3.91  ...  130.42  2387.66  8072.30   9.3774  0.02  330  2212  100.00   \n2  7.05  ...  164.22  2028.03  7864.87  10.8941  0.02  309  1915   84.93   \n3  3.91  ...  130.72  2387.61  8068.66   9.3528  0.02  329  2212  100.00   \n4  7.05  ...  164.31  2028.00  7861.23  10.8963  0.02  309  1915   84.93   \n\n     s20     s21  \n0  14.73  8.8071  \n1  10.41  6.2665  \n2  14.08  8.6723  \n3  10.59  6.4701  \n4  14.13  8.5286  \n\n[5 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cycle</th>\n      <th>setting1</th>\n      <th>setting2</th>\n      <th>setting3</th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>s3</th>\n      <th>s4</th>\n      <th>s5</th>\n      <th>...</th>\n      <th>s12</th>\n      <th>s13</th>\n      <th>s14</th>\n      <th>s15</th>\n      <th>s16</th>\n      <th>s17</th>\n      <th>s18</th>\n      <th>s19</th>\n      <th>s20</th>\n      <th>s21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>34.9983</td>\n      <td>0.8400</td>\n      <td>100.0</td>\n      <td>449.44</td>\n      <td>555.32</td>\n      <td>1358.61</td>\n      <td>1137.23</td>\n      <td>5.48</td>\n      <td>...</td>\n      <td>183.06</td>\n      <td>2387.72</td>\n      <td>8048.56</td>\n      <td>9.3461</td>\n      <td>0.02</td>\n      <td>334</td>\n      <td>2223</td>\n      <td>100.00</td>\n      <td>14.73</td>\n      <td>8.8071</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>41.9982</td>\n      <td>0.8408</td>\n      <td>100.0</td>\n      <td>445.00</td>\n      <td>549.90</td>\n      <td>1353.22</td>\n      <td>1125.78</td>\n      <td>3.91</td>\n      <td>...</td>\n      <td>130.42</td>\n      <td>2387.66</td>\n      <td>8072.30</td>\n      <td>9.3774</td>\n      <td>0.02</td>\n      <td>330</td>\n      <td>2212</td>\n      <td>100.00</td>\n      <td>10.41</td>\n      <td>6.2665</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>24.9988</td>\n      <td>0.6218</td>\n      <td>60.0</td>\n      <td>462.54</td>\n      <td>537.31</td>\n      <td>1256.76</td>\n      <td>1047.45</td>\n      <td>7.05</td>\n      <td>...</td>\n      <td>164.22</td>\n      <td>2028.03</td>\n      <td>7864.87</td>\n      <td>10.8941</td>\n      <td>0.02</td>\n      <td>309</td>\n      <td>1915</td>\n      <td>84.93</td>\n      <td>14.08</td>\n      <td>8.6723</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>42.0077</td>\n      <td>0.8416</td>\n      <td>100.0</td>\n      <td>445.00</td>\n      <td>549.51</td>\n      <td>1354.03</td>\n      <td>1126.38</td>\n      <td>3.91</td>\n      <td>...</td>\n      <td>130.72</td>\n      <td>2387.61</td>\n      <td>8068.66</td>\n      <td>9.3528</td>\n      <td>0.02</td>\n      <td>329</td>\n      <td>2212</td>\n      <td>100.00</td>\n      <td>10.59</td>\n      <td>6.4701</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>25.0005</td>\n      <td>0.6203</td>\n      <td>60.0</td>\n      <td>462.54</td>\n      <td>537.07</td>\n      <td>1257.71</td>\n      <td>1047.93</td>\n      <td>7.05</td>\n      <td>...</td>\n      <td>164.31</td>\n      <td>2028.00</td>\n      <td>7861.23</td>\n      <td>10.8963</td>\n      <td>0.02</td>\n      <td>309</td>\n      <td>1915</td>\n      <td>84.93</td>\n      <td>14.13</td>\n      <td>8.5286</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "jet = pd.read_table('../train_data.txt',sep=' ',header=None)\n",
    "jet.drop([26,27],axis=1,inplace=True)\n",
    "jet.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "train_df = jet\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n0   1      1    9.9987    0.2502     100.0  489.05  605.03  1497.17  1304.99   \n1   1      2   20.0026    0.7000     100.0  491.19  607.82  1481.20  1246.11   \n2   1      3   35.0045    0.8400     100.0  449.44  556.00  1359.08  1128.36   \n3   1      4   42.0066    0.8410     100.0  445.00  550.17  1349.69  1127.89   \n4   1      5   24.9985    0.6213      60.0  462.54  536.72  1253.18  1050.69   \n\n      s5  ...     s12      s13      s14      s15   s16  s17   s18     s19  \\\n0  10.52  ...  371.69  2388.18  8114.10   8.6476  0.03  369  2319  100.00   \n1   9.35  ...  315.32  2388.12  8053.06   9.2405  0.02  364  2324  100.00   \n2   5.48  ...  183.04  2387.75  8053.04   9.3472  0.02  333  2223  100.00   \n3   3.91  ...  130.40  2387.72  8066.90   9.3961  0.02  332  2212  100.00   \n4   7.05  ...  164.56  2028.05  7865.66  10.8682  0.02  305  1915   84.93   \n\n     s20      s21  \n0  28.42  17.1551  \n1  24.29  14.8039  \n2  14.98   8.9125  \n3  10.35   6.4181  \n4  14.31   8.5740  \n\n[5 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cycle</th>\n      <th>setting1</th>\n      <th>setting2</th>\n      <th>setting3</th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>s3</th>\n      <th>s4</th>\n      <th>s5</th>\n      <th>...</th>\n      <th>s12</th>\n      <th>s13</th>\n      <th>s14</th>\n      <th>s15</th>\n      <th>s16</th>\n      <th>s17</th>\n      <th>s18</th>\n      <th>s19</th>\n      <th>s20</th>\n      <th>s21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>9.9987</td>\n      <td>0.2502</td>\n      <td>100.0</td>\n      <td>489.05</td>\n      <td>605.03</td>\n      <td>1497.17</td>\n      <td>1304.99</td>\n      <td>10.52</td>\n      <td>...</td>\n      <td>371.69</td>\n      <td>2388.18</td>\n      <td>8114.10</td>\n      <td>8.6476</td>\n      <td>0.03</td>\n      <td>369</td>\n      <td>2319</td>\n      <td>100.00</td>\n      <td>28.42</td>\n      <td>17.1551</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>20.0026</td>\n      <td>0.7000</td>\n      <td>100.0</td>\n      <td>491.19</td>\n      <td>607.82</td>\n      <td>1481.20</td>\n      <td>1246.11</td>\n      <td>9.35</td>\n      <td>...</td>\n      <td>315.32</td>\n      <td>2388.12</td>\n      <td>8053.06</td>\n      <td>9.2405</td>\n      <td>0.02</td>\n      <td>364</td>\n      <td>2324</td>\n      <td>100.00</td>\n      <td>24.29</td>\n      <td>14.8039</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>35.0045</td>\n      <td>0.8400</td>\n      <td>100.0</td>\n      <td>449.44</td>\n      <td>556.00</td>\n      <td>1359.08</td>\n      <td>1128.36</td>\n      <td>5.48</td>\n      <td>...</td>\n      <td>183.04</td>\n      <td>2387.75</td>\n      <td>8053.04</td>\n      <td>9.3472</td>\n      <td>0.02</td>\n      <td>333</td>\n      <td>2223</td>\n      <td>100.00</td>\n      <td>14.98</td>\n      <td>8.9125</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>42.0066</td>\n      <td>0.8410</td>\n      <td>100.0</td>\n      <td>445.00</td>\n      <td>550.17</td>\n      <td>1349.69</td>\n      <td>1127.89</td>\n      <td>3.91</td>\n      <td>...</td>\n      <td>130.40</td>\n      <td>2387.72</td>\n      <td>8066.90</td>\n      <td>9.3961</td>\n      <td>0.02</td>\n      <td>332</td>\n      <td>2212</td>\n      <td>100.00</td>\n      <td>10.35</td>\n      <td>6.4181</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>24.9985</td>\n      <td>0.6213</td>\n      <td>60.0</td>\n      <td>462.54</td>\n      <td>536.72</td>\n      <td>1253.18</td>\n      <td>1050.69</td>\n      <td>7.05</td>\n      <td>...</td>\n      <td>164.56</td>\n      <td>2028.05</td>\n      <td>7865.66</td>\n      <td>10.8682</td>\n      <td>0.02</td>\n      <td>305</td>\n      <td>1915</td>\n      <td>84.93</td>\n      <td>14.31</td>\n      <td>8.5740</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "td = pd.read_table('../test_data.txt',sep=' ',header=None)\n",
    "td.drop([26,27],axis=1,inplace=True)\n",
    "td.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "td.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "21"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "td.groupby('id').max()['cycle'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_cluster = cluster.KMeans(n_clusters=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_min_normalize(df):\n",
    "    return (df-df.min())/(df.max()-df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = jet[['setting1','setting2','setting3']]\n",
    "test_feature = td[['setting1','setting2','setting3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(max_min_normalize(feature))\n",
    "test_data = np.array(max_min_normalize(test_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n       n_clusters=6, n_init=10, n_jobs=None, precompute_distances='auto',\n       random_state=None, tol=0.0001, verbose=0)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "k_cluster.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mode = pd.DataFrame(k_cluster.labels_)\n",
    "test_mode = pd.DataFrame(k_cluster.predict(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['mode1']=0\n",
    "train_df['mode2']=0\n",
    "train_df['mode3']=0\n",
    "train_df['mode4']=0\n",
    "train_df['mode5']=0\n",
    "train_df['mode6']=0\n",
    "train_df.loc[train_mode[0]==0,['mode1','mode2','mode3','mode4','mode5','mode6']]=[1,0,0,0,0,0]\n",
    "train_df.loc[train_mode[0]==1,['mode1','mode2','mode3','mode4','mode5','mode6']]=[0,1,0,0,0,0]\n",
    "train_df.loc[train_mode[0]==2,['mode1','mode2','mode3','mode4','mode5','mode6']]=[0,0,1,0,0,0]\n",
    "train_df.loc[train_mode[0]==3,['mode1','mode2','mode3','mode4','mode5','mode6']]=[0,0,0,1,0,0]\n",
    "train_df.loc[train_mode[0]==4,['mode1','mode2','mode3','mode4','mode5','mode6']]=[0,0,0,0,1,0]\n",
    "train_df.loc[train_mode[0]==5,['mode1','mode2','mode3','mode4','mode5','mode6']]=[0,0,0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "td['mode1']=0\n",
    "td['mode2']=0\n",
    "td['mode3']=0\n",
    "td['mode4']=0\n",
    "td['mode5']=0\n",
    "td['mode6']=0\n",
    "td.loc[test_mode[0]==0,['mode1','mode2','mode3','mode4','mode5','mode6']]=[1,0,0,0,0,0]\n",
    "td.loc[test_mode[0]==1,['mode1','mode2','mode3','mode4','mode5','mode6']]=[0,1,0,0,0,0]\n",
    "td.loc[test_mode[0]==2,['mode1','mode2','mode3','mode4','mode5','mode6']]=[0,0,1,0,0,0]\n",
    "td.loc[test_mode[0]==3,['mode1','mode2','mode3','mode4','mode5','mode6']]=[0,0,0,1,0,0]\n",
    "td.loc[test_mode[0]==4,['mode1','mode2','mode3','mode4','mode5','mode6']]=[0,0,0,0,1,0]\n",
    "td.loc[test_mode[0]==5,['mode1','mode2','mode3','mode4','mode5','mode6']]=[0,0,0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n0   1      1   34.9983    0.8400     100.0  449.44  555.32  1358.61  1137.23   \n1   1      2   41.9982    0.8408     100.0  445.00  549.90  1353.22  1125.78   \n2   1      3   24.9988    0.6218      60.0  462.54  537.31  1256.76  1047.45   \n3   1      4   42.0077    0.8416     100.0  445.00  549.51  1354.03  1126.38   \n4   1      5   25.0005    0.6203      60.0  462.54  537.07  1257.71  1047.93   \n\n     s5  ...     s19    s20     s21  mode1  mode2  mode3  mode4  mode5  mode6  \\\n0  5.48  ...  100.00  14.73  8.8071      0      1      0      0      0      0   \n1  3.91  ...  100.00  10.41  6.2665      0      0      0      0      0      1   \n2  7.05  ...   84.93  14.08  8.6723      1      0      0      0      0      0   \n3  3.91  ...  100.00  10.59  6.4701      0      0      0      0      0      1   \n4  7.05  ...   84.93  14.13  8.5286      1      0      0      0      0      0   \n\n   RUL  \n0  130  \n1  130  \n2  130  \n3  130  \n4  130  \n\n[5 rows x 33 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cycle</th>\n      <th>setting1</th>\n      <th>setting2</th>\n      <th>setting3</th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>s3</th>\n      <th>s4</th>\n      <th>s5</th>\n      <th>...</th>\n      <th>s19</th>\n      <th>s20</th>\n      <th>s21</th>\n      <th>mode1</th>\n      <th>mode2</th>\n      <th>mode3</th>\n      <th>mode4</th>\n      <th>mode5</th>\n      <th>mode6</th>\n      <th>RUL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>34.9983</td>\n      <td>0.8400</td>\n      <td>100.0</td>\n      <td>449.44</td>\n      <td>555.32</td>\n      <td>1358.61</td>\n      <td>1137.23</td>\n      <td>5.48</td>\n      <td>...</td>\n      <td>100.00</td>\n      <td>14.73</td>\n      <td>8.8071</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>41.9982</td>\n      <td>0.8408</td>\n      <td>100.0</td>\n      <td>445.00</td>\n      <td>549.90</td>\n      <td>1353.22</td>\n      <td>1125.78</td>\n      <td>3.91</td>\n      <td>...</td>\n      <td>100.00</td>\n      <td>10.41</td>\n      <td>6.2665</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>24.9988</td>\n      <td>0.6218</td>\n      <td>60.0</td>\n      <td>462.54</td>\n      <td>537.31</td>\n      <td>1256.76</td>\n      <td>1047.45</td>\n      <td>7.05</td>\n      <td>...</td>\n      <td>84.93</td>\n      <td>14.08</td>\n      <td>8.6723</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>42.0077</td>\n      <td>0.8416</td>\n      <td>100.0</td>\n      <td>445.00</td>\n      <td>549.51</td>\n      <td>1354.03</td>\n      <td>1126.38</td>\n      <td>3.91</td>\n      <td>...</td>\n      <td>100.00</td>\n      <td>10.59</td>\n      <td>6.4701</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>25.0005</td>\n      <td>0.6203</td>\n      <td>60.0</td>\n      <td>462.54</td>\n      <td>537.07</td>\n      <td>1257.71</td>\n      <td>1047.93</td>\n      <td>7.05</td>\n      <td>...</td>\n      <td>84.93</td>\n      <td>14.13</td>\n      <td>8.5286</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>130</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 33 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Data Labeling - generate column RUL\n",
    "rul = pd.DataFrame(train_df.groupby('id')['cycle'].max()).reset_index()\n",
    "rul.columns = ['id', 'max']\n",
    "train_df = train_df.merge(rul, on=['id'], how='left')\n",
    "train_df['RUL'] = train_df['max'] - train_df['cycle']\n",
    "train_df.drop('max', axis=1, inplace=True)\n",
    "train_df.loc[train_df['RUL']>130,['RUL']]=130\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        id  cycle  setting1  setting2  setting3        s1        s2        s3  \\\n0        1      1  0.833134  0.997625       1.0  0.060269  0.181576  0.311201   \n1        1      2  0.999767  0.998575       1.0  0.000000  0.131847  0.296600   \n2        1      3  0.595096  0.738480       0.0  0.238089  0.016332  0.035297   \n3        1      4  0.999993  0.999525       1.0  0.000000  0.128269  0.298795   \n4        1      5  0.595137  0.736698       0.0  0.238089  0.014130  0.037871   \n...    ...    ...       ...       ...       ...       ...       ...       ...   \n53754  260    312  0.476188  0.831354       1.0  0.626985  0.672172  0.682297   \n53755  260    313  0.238102  0.298100       1.0  0.597937  0.644830  0.733008   \n53756  260    314  0.595222  0.736342       0.0  0.238089  0.017892  0.088067   \n53757  260    315  0.595203  0.738717       0.0  0.238089  0.021195  0.079155   \n53758  260    316  0.833260  0.997625       1.0  0.060269  0.193687  0.354544   \n\n             s4        s5  ...       s20       s21  mode1  mode2  mode3  \\\n0      0.273095  0.146592  ...  0.156036  0.159082    0.0    1.0    0.0   \n1      0.245535  0.000000  ...  0.007888  0.014562    0.0    0.0    0.0   \n2      0.056997  0.293184  ...  0.133745  0.151414    1.0    0.0    0.0   \n3      0.246979  0.000000  ...  0.014060  0.026144    0.0    0.0    0.0   \n4      0.058152  0.293184  ...  0.135460  0.143240    1.0    0.0    0.0   \n...         ...       ...  ...       ...       ...    ...    ...    ...   \n53754  0.591489  0.507937  ...  0.486283  0.483993    0.0    0.0    0.0   \n53755  0.722934  0.617180  ...  0.614540  0.622022    0.0    0.0    0.0   \n53756  0.082198  0.293184  ...  0.137517  0.144474    1.0    0.0    0.0   \n53757  0.102368  0.293184  ...  0.132716  0.134383    1.0    0.0    0.0   \n53758  0.293049  0.146592  ...  0.156722  0.161215    0.0    1.0    0.0   \n\n       mode4  mode5  mode6  RUL  cycle_norm  \n0        0.0    0.0    0.0  130    0.000000  \n1        0.0    0.0    1.0  130    0.002653  \n2        0.0    0.0    0.0  130    0.005305  \n3        0.0    0.0    1.0  130    0.007958  \n4        0.0    0.0    0.0  130    0.010610  \n...      ...    ...    ...  ...         ...  \n53754    1.0    0.0    0.0    4    0.824934  \n53755    0.0    1.0    0.0    3    0.827586  \n53756    0.0    0.0    0.0    2    0.830239  \n53757    0.0    0.0    0.0    1    0.832891  \n53758    0.0    0.0    0.0    0    0.835544  \n\n[53759 rows x 34 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cycle</th>\n      <th>setting1</th>\n      <th>setting2</th>\n      <th>setting3</th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>s3</th>\n      <th>s4</th>\n      <th>s5</th>\n      <th>...</th>\n      <th>s20</th>\n      <th>s21</th>\n      <th>mode1</th>\n      <th>mode2</th>\n      <th>mode3</th>\n      <th>mode4</th>\n      <th>mode5</th>\n      <th>mode6</th>\n      <th>RUL</th>\n      <th>cycle_norm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.833134</td>\n      <td>0.997625</td>\n      <td>1.0</td>\n      <td>0.060269</td>\n      <td>0.181576</td>\n      <td>0.311201</td>\n      <td>0.273095</td>\n      <td>0.146592</td>\n      <td>...</td>\n      <td>0.156036</td>\n      <td>0.159082</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>130</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.999767</td>\n      <td>0.998575</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.131847</td>\n      <td>0.296600</td>\n      <td>0.245535</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.007888</td>\n      <td>0.014562</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>130</td>\n      <td>0.002653</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0.595096</td>\n      <td>0.738480</td>\n      <td>0.0</td>\n      <td>0.238089</td>\n      <td>0.016332</td>\n      <td>0.035297</td>\n      <td>0.056997</td>\n      <td>0.293184</td>\n      <td>...</td>\n      <td>0.133745</td>\n      <td>0.151414</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>130</td>\n      <td>0.005305</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.999993</td>\n      <td>0.999525</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.128269</td>\n      <td>0.298795</td>\n      <td>0.246979</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.014060</td>\n      <td>0.026144</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>130</td>\n      <td>0.007958</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>0.595137</td>\n      <td>0.736698</td>\n      <td>0.0</td>\n      <td>0.238089</td>\n      <td>0.014130</td>\n      <td>0.037871</td>\n      <td>0.058152</td>\n      <td>0.293184</td>\n      <td>...</td>\n      <td>0.135460</td>\n      <td>0.143240</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>130</td>\n      <td>0.010610</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>53754</th>\n      <td>260</td>\n      <td>312</td>\n      <td>0.476188</td>\n      <td>0.831354</td>\n      <td>1.0</td>\n      <td>0.626985</td>\n      <td>0.672172</td>\n      <td>0.682297</td>\n      <td>0.591489</td>\n      <td>0.507937</td>\n      <td>...</td>\n      <td>0.486283</td>\n      <td>0.483993</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.824934</td>\n    </tr>\n    <tr>\n      <th>53755</th>\n      <td>260</td>\n      <td>313</td>\n      <td>0.238102</td>\n      <td>0.298100</td>\n      <td>1.0</td>\n      <td>0.597937</td>\n      <td>0.644830</td>\n      <td>0.733008</td>\n      <td>0.722934</td>\n      <td>0.617180</td>\n      <td>...</td>\n      <td>0.614540</td>\n      <td>0.622022</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.827586</td>\n    </tr>\n    <tr>\n      <th>53756</th>\n      <td>260</td>\n      <td>314</td>\n      <td>0.595222</td>\n      <td>0.736342</td>\n      <td>0.0</td>\n      <td>0.238089</td>\n      <td>0.017892</td>\n      <td>0.088067</td>\n      <td>0.082198</td>\n      <td>0.293184</td>\n      <td>...</td>\n      <td>0.137517</td>\n      <td>0.144474</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0.830239</td>\n    </tr>\n    <tr>\n      <th>53757</th>\n      <td>260</td>\n      <td>315</td>\n      <td>0.595203</td>\n      <td>0.738717</td>\n      <td>0.0</td>\n      <td>0.238089</td>\n      <td>0.021195</td>\n      <td>0.079155</td>\n      <td>0.102368</td>\n      <td>0.293184</td>\n      <td>...</td>\n      <td>0.132716</td>\n      <td>0.134383</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0.832891</td>\n    </tr>\n    <tr>\n      <th>53758</th>\n      <td>260</td>\n      <td>316</td>\n      <td>0.833260</td>\n      <td>0.997625</td>\n      <td>1.0</td>\n      <td>0.060269</td>\n      <td>0.193687</td>\n      <td>0.354544</td>\n      <td>0.293049</td>\n      <td>0.146592</td>\n      <td>...</td>\n      <td>0.156722</td>\n      <td>0.161215</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.835544</td>\n    </tr>\n  </tbody>\n</table>\n<p>53759 rows × 34 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# normalize the columns in the training data.\n",
    "# MinMax normalization\n",
    "train_df['cycle_norm'] = train_df['cycle']\n",
    "cols_normalize = train_df.columns.difference(['id','cycle','RUL'])\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]), \n",
    "                             columns=cols_normalize, \n",
    "                             index=train_df.index)\n",
    "join_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\n",
    "train_df = join_df.reindex(columns = train_df.columns)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        id  cycle  setting1  setting2  setting3        s1        s2        s3  \\\n0        1      1  0.238019  0.297150       1.0  0.597937  0.639243  0.691329   \n1        1      2  0.476162  0.831354       1.0  0.626985  0.664861  0.647519   \n2        1      3  0.833282  0.997625       1.0  0.060269  0.189055  0.312512   \n3        1      4  0.999967  0.998812       1.0  0.000000  0.135525  0.286753   \n4        1      5  0.595089  0.737886       0.0  0.238089  0.012028  0.022001   \n...    ...    ...       ...       ...       ...       ...       ...       ...   \n33986  259    119  0.833210  0.997981       1.0  0.060269  0.185015  0.331523   \n33987  259    120  0.999967  0.998219       1.0  0.000000  0.128638  0.290703   \n33988  259    121  0.999955  0.997625       1.0  0.000000  0.130750  0.285244   \n33989  259    122  0.000057  0.000356       1.0  1.000000  0.984024  0.944915   \n33990  259    123  0.999888  0.997625       1.0  0.000000  0.131852  0.267029   \n\n             s4        s5  ...  s19       s20       s21  mode1  mode2  mode3  \\\n0      0.680395  0.617180  ...  1.0  0.625944  0.630724    0.0    0.0    0.0   \n1      0.534663  0.507937  ...  1.0  0.484214  0.496301    0.0    0.0    0.0   \n2      0.243225  0.146592  ...  1.0  0.164722  0.159476    0.0    1.0    0.0   \n3      0.242061  0.000000  ...  1.0  0.005834  0.016866    0.0    0.0    0.0   \n4      0.050986  0.293184  ...  0.0  0.141730  0.140123    1.0    0.0    0.0   \n...         ...       ...  ...  ...       ...       ...    ...    ...    ...   \n33986  0.245972  0.146592  ...  1.0  0.163349  0.159133    0.0    1.0    0.0   \n33987  0.232087  0.000000  ...  1.0  0.013384  0.016260    0.0    0.0    0.0   \n33988  0.219835  0.000000  ...  1.0  0.013384  0.020433    0.0    0.0    0.0   \n33989  0.935747  1.000000  ...  1.0  0.991764  0.985410    0.0    0.0    1.0   \n33990  0.239759  0.000000  ...  1.0  0.015443  0.012858    0.0    0.0    0.0   \n\n       mode4  mode5  mode6  cycle_norm  \n0        0.0    1.0    0.0    0.000000  \n1        1.0    0.0    0.0    0.002732  \n2        0.0    0.0    0.0    0.005464  \n3        0.0    0.0    1.0    0.008197  \n4        0.0    0.0    0.0    0.010929  \n...      ...    ...    ...         ...  \n33986    0.0    0.0    0.0    0.322404  \n33987    0.0    0.0    1.0    0.325137  \n33988    0.0    0.0    1.0    0.327869  \n33989    0.0    0.0    0.0    0.330601  \n33990    0.0    0.0    1.0    0.333333  \n\n[33991 rows x 33 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cycle</th>\n      <th>setting1</th>\n      <th>setting2</th>\n      <th>setting3</th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>s3</th>\n      <th>s4</th>\n      <th>s5</th>\n      <th>...</th>\n      <th>s19</th>\n      <th>s20</th>\n      <th>s21</th>\n      <th>mode1</th>\n      <th>mode2</th>\n      <th>mode3</th>\n      <th>mode4</th>\n      <th>mode5</th>\n      <th>mode6</th>\n      <th>cycle_norm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.238019</td>\n      <td>0.297150</td>\n      <td>1.0</td>\n      <td>0.597937</td>\n      <td>0.639243</td>\n      <td>0.691329</td>\n      <td>0.680395</td>\n      <td>0.617180</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.625944</td>\n      <td>0.630724</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.476162</td>\n      <td>0.831354</td>\n      <td>1.0</td>\n      <td>0.626985</td>\n      <td>0.664861</td>\n      <td>0.647519</td>\n      <td>0.534663</td>\n      <td>0.507937</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.484214</td>\n      <td>0.496301</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.002732</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0.833282</td>\n      <td>0.997625</td>\n      <td>1.0</td>\n      <td>0.060269</td>\n      <td>0.189055</td>\n      <td>0.312512</td>\n      <td>0.243225</td>\n      <td>0.146592</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.164722</td>\n      <td>0.159476</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.005464</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.999967</td>\n      <td>0.998812</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.135525</td>\n      <td>0.286753</td>\n      <td>0.242061</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.005834</td>\n      <td>0.016866</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.008197</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>0.595089</td>\n      <td>0.737886</td>\n      <td>0.0</td>\n      <td>0.238089</td>\n      <td>0.012028</td>\n      <td>0.022001</td>\n      <td>0.050986</td>\n      <td>0.293184</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.141730</td>\n      <td>0.140123</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.010929</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33986</th>\n      <td>259</td>\n      <td>119</td>\n      <td>0.833210</td>\n      <td>0.997981</td>\n      <td>1.0</td>\n      <td>0.060269</td>\n      <td>0.185015</td>\n      <td>0.331523</td>\n      <td>0.245972</td>\n      <td>0.146592</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.163349</td>\n      <td>0.159133</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.322404</td>\n    </tr>\n    <tr>\n      <th>33987</th>\n      <td>259</td>\n      <td>120</td>\n      <td>0.999967</td>\n      <td>0.998219</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.128638</td>\n      <td>0.290703</td>\n      <td>0.232087</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.013384</td>\n      <td>0.016260</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.325137</td>\n    </tr>\n    <tr>\n      <th>33988</th>\n      <td>259</td>\n      <td>121</td>\n      <td>0.999955</td>\n      <td>0.997625</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.130750</td>\n      <td>0.285244</td>\n      <td>0.219835</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.013384</td>\n      <td>0.020433</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.327869</td>\n    </tr>\n    <tr>\n      <th>33989</th>\n      <td>259</td>\n      <td>122</td>\n      <td>0.000057</td>\n      <td>0.000356</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.984024</td>\n      <td>0.944915</td>\n      <td>0.935747</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.991764</td>\n      <td>0.985410</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.330601</td>\n    </tr>\n    <tr>\n      <th>33990</th>\n      <td>259</td>\n      <td>123</td>\n      <td>0.999888</td>\n      <td>0.997625</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.131852</td>\n      <td>0.267029</td>\n      <td>0.239759</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.015443</td>\n      <td>0.012858</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n    </tr>\n  </tbody>\n</table>\n<p>33991 rows × 33 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# normalize the columns in the test data.\n",
    "# MinMax normalization\n",
    "td['cycle_norm'] = td['cycle']\n",
    "cols_normalize = td.columns.difference(['id','cycle'])\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(td[cols_normalize]), \n",
    "                             columns=cols_normalize, \n",
    "                             index=td.index)\n",
    "join_df = td[td.columns.difference(cols_normalize)].join(norm_train_df)\n",
    "td = join_df.reindex(columns = td.columns)\n",
    "td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存已处理的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/processed_train_data')\n",
    "td = pd.read_csv('./data/processed_test_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        id  cycle  setting1  setting2  setting3        s1        s2        s3  \\\n0        1      1  0.833134  0.997625       1.0  0.060269  0.181576  0.311201   \n1        1      2  0.999767  0.998575       1.0  0.000000  0.131847  0.296600   \n2        1      3  0.595096  0.738480       0.0  0.238089  0.016332  0.035297   \n3        1      4  0.999993  0.999525       1.0  0.000000  0.128269  0.298795   \n4        1      5  0.595137  0.736698       0.0  0.238089  0.014130  0.037871   \n...    ...    ...       ...       ...       ...       ...       ...       ...   \n53754  260    312  0.476188  0.831354       1.0  0.626985  0.672172  0.682297   \n53755  260    313  0.238102  0.298100       1.0  0.597937  0.644830  0.733008   \n53756  260    314  0.595222  0.736342       0.0  0.238089  0.017892  0.088067   \n53757  260    315  0.595203  0.738717       0.0  0.238089  0.021195  0.079155   \n53758  260    316  0.833260  0.997625       1.0  0.060269  0.193687  0.354544   \n\n             s4        s5  ...       s20       s21  mode1  mode2  mode3  \\\n0      0.273095  0.146592  ...  0.156036  0.159082    0.0    1.0    0.0   \n1      0.245535  0.000000  ...  0.007888  0.014562    0.0    0.0    0.0   \n2      0.056997  0.293184  ...  0.133745  0.151414    1.0    0.0    0.0   \n3      0.246979  0.000000  ...  0.014060  0.026144    0.0    0.0    0.0   \n4      0.058152  0.293184  ...  0.135460  0.143240    1.0    0.0    0.0   \n...         ...       ...  ...       ...       ...    ...    ...    ...   \n53754  0.591489  0.507937  ...  0.486283  0.483993    0.0    0.0    0.0   \n53755  0.722934  0.617180  ...  0.614540  0.622022    0.0    0.0    0.0   \n53756  0.082198  0.293184  ...  0.137517  0.144474    1.0    0.0    0.0   \n53757  0.102368  0.293184  ...  0.132716  0.134383    1.0    0.0    0.0   \n53758  0.293049  0.146592  ...  0.156722  0.161215    0.0    1.0    0.0   \n\n       mode4  mode5  mode6  RUL  cycle_norm  \n0        0.0    0.0    0.0  130    0.000000  \n1        0.0    0.0    1.0  130    0.002653  \n2        0.0    0.0    0.0  130    0.005305  \n3        0.0    0.0    1.0  130    0.007958  \n4        0.0    0.0    0.0  130    0.010610  \n...      ...    ...    ...  ...         ...  \n53754    1.0    0.0    0.0    4    0.824934  \n53755    0.0    1.0    0.0    3    0.827586  \n53756    0.0    0.0    0.0    2    0.830239  \n53757    0.0    0.0    0.0    1    0.832891  \n53758    0.0    0.0    0.0    0    0.835544  \n\n[53759 rows x 34 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cycle</th>\n      <th>setting1</th>\n      <th>setting2</th>\n      <th>setting3</th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>s3</th>\n      <th>s4</th>\n      <th>s5</th>\n      <th>...</th>\n      <th>s20</th>\n      <th>s21</th>\n      <th>mode1</th>\n      <th>mode2</th>\n      <th>mode3</th>\n      <th>mode4</th>\n      <th>mode5</th>\n      <th>mode6</th>\n      <th>RUL</th>\n      <th>cycle_norm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.833134</td>\n      <td>0.997625</td>\n      <td>1.0</td>\n      <td>0.060269</td>\n      <td>0.181576</td>\n      <td>0.311201</td>\n      <td>0.273095</td>\n      <td>0.146592</td>\n      <td>...</td>\n      <td>0.156036</td>\n      <td>0.159082</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>130</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.999767</td>\n      <td>0.998575</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.131847</td>\n      <td>0.296600</td>\n      <td>0.245535</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.007888</td>\n      <td>0.014562</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>130</td>\n      <td>0.002653</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0.595096</td>\n      <td>0.738480</td>\n      <td>0.0</td>\n      <td>0.238089</td>\n      <td>0.016332</td>\n      <td>0.035297</td>\n      <td>0.056997</td>\n      <td>0.293184</td>\n      <td>...</td>\n      <td>0.133745</td>\n      <td>0.151414</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>130</td>\n      <td>0.005305</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.999993</td>\n      <td>0.999525</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.128269</td>\n      <td>0.298795</td>\n      <td>0.246979</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.014060</td>\n      <td>0.026144</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>130</td>\n      <td>0.007958</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>0.595137</td>\n      <td>0.736698</td>\n      <td>0.0</td>\n      <td>0.238089</td>\n      <td>0.014130</td>\n      <td>0.037871</td>\n      <td>0.058152</td>\n      <td>0.293184</td>\n      <td>...</td>\n      <td>0.135460</td>\n      <td>0.143240</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>130</td>\n      <td>0.010610</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>53754</th>\n      <td>260</td>\n      <td>312</td>\n      <td>0.476188</td>\n      <td>0.831354</td>\n      <td>1.0</td>\n      <td>0.626985</td>\n      <td>0.672172</td>\n      <td>0.682297</td>\n      <td>0.591489</td>\n      <td>0.507937</td>\n      <td>...</td>\n      <td>0.486283</td>\n      <td>0.483993</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.824934</td>\n    </tr>\n    <tr>\n      <th>53755</th>\n      <td>260</td>\n      <td>313</td>\n      <td>0.238102</td>\n      <td>0.298100</td>\n      <td>1.0</td>\n      <td>0.597937</td>\n      <td>0.644830</td>\n      <td>0.733008</td>\n      <td>0.722934</td>\n      <td>0.617180</td>\n      <td>...</td>\n      <td>0.614540</td>\n      <td>0.622022</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.827586</td>\n    </tr>\n    <tr>\n      <th>53756</th>\n      <td>260</td>\n      <td>314</td>\n      <td>0.595222</td>\n      <td>0.736342</td>\n      <td>0.0</td>\n      <td>0.238089</td>\n      <td>0.017892</td>\n      <td>0.088067</td>\n      <td>0.082198</td>\n      <td>0.293184</td>\n      <td>...</td>\n      <td>0.137517</td>\n      <td>0.144474</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0.830239</td>\n    </tr>\n    <tr>\n      <th>53757</th>\n      <td>260</td>\n      <td>315</td>\n      <td>0.595203</td>\n      <td>0.738717</td>\n      <td>0.0</td>\n      <td>0.238089</td>\n      <td>0.021195</td>\n      <td>0.079155</td>\n      <td>0.102368</td>\n      <td>0.293184</td>\n      <td>...</td>\n      <td>0.132716</td>\n      <td>0.134383</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0.832891</td>\n    </tr>\n    <tr>\n      <th>53758</th>\n      <td>260</td>\n      <td>316</td>\n      <td>0.833260</td>\n      <td>0.997625</td>\n      <td>1.0</td>\n      <td>0.060269</td>\n      <td>0.193687</td>\n      <td>0.354544</td>\n      <td>0.293049</td>\n      <td>0.146592</td>\n      <td>...</td>\n      <td>0.156722</td>\n      <td>0.161215</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.835544</td>\n    </tr>\n  </tbody>\n</table>\n<p>53759 rows × 34 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "128"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "train_df.groupby('id').max()['cycle'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reshape features into (samples, time steps, features) \n",
    "def gen_sequence(id_df, seq_length, seq_cols):\n",
    "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
    "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
    "    we can use shorter ones \"\"\"\n",
    "    data_array = id_df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "        yield data_array[start:stop, :]\n",
    "    # For example id1 have 192 rows and sequence_length is equal to 50\n",
    "    # so zip iterate over two following list of numbers (0,112),(50,192)\n",
    "    # 0 50 -> from row 0 to row 50\n",
    "    # 1 51 -> from row 1 to row 51\n",
    "    # 2 52 -> from row 2 to row 52\n",
    "    # ...\n",
    "    # 111 191 -> from row 111 to 191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the feature columns \n",
    "sensor_cols = ['s' + str(i) for i in range(1,22)]\n",
    "sequence_cols = ['setting1', 'setting2', 'setting3','cycle_norm','mode1','mode2','mode3','mode4','mode5','mode6']\n",
    "# sequence_cols = ['setting1', 'setting2', 'setting3','cycle_norm']\n",
    "sequence_cols.extend(sensor_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(40759, 50, 31)"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# generator for the sequences\n",
    "seq_gen = (list(gen_sequence(train_df[train_df['id']==id], sequence_length, sequence_cols)) \n",
    "           for id in train_df['id'].unique())\n",
    "\n",
    "# generate sequences and convert to numpy array\n",
    "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
    "seq_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate labels\n",
    "def gen_labels(id_df, seq_length, label):\n",
    "    data_array = id_df[label].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    return data_array[seq_length:num_elements, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[98.],\n       [97.],\n       [96.],\n       ...,\n       [ 2.],\n       [ 1.],\n       [ 0.]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# generate labels\n",
    "label_gen = [gen_labels(train_df[train_df['id']==id], sequence_length, ['RUL']) \n",
    "             for id in train_df['id'].unique()]\n",
    "label_array = np.concatenate(label_gen).astype(np.float32)\n",
    "label_array.shape\n",
    "label_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model with mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_keras(y_true, y_pred):\n",
    "    \"\"\"Coefficient of Determination \n",
    "    \"\"\"\n",
    "    SS_res =  K.sum(K.square( y_true - y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /Users/zhehaoyu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\nWARNING:tensorflow:From /Users/zhehaoyu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n\nWARNING:tensorflow:From /Users/zhehaoyu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nWARNING:tensorflow:From /Users/zhehaoyu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n\nWARNING:tensorflow:From /Users/zhehaoyu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\nWARNING:tensorflow:From /Users/zhehaoyu/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nmasking_1 (Masking)          (None, 50, 31)            0         \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 50, 100)           52800     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 50, 100)           0         \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 50)                30200     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 50)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 51        \n_________________________________________________________________\nactivation_1 (Activation)    (None, 1)                 0         \n=================================================================\nTotal params: 83,051\nTrainable params: 83,051\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "# Build model with mask\n",
    "nb_features = seq_array.shape[2]\n",
    "nb_out = label_array.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Masking(mask_value=0., input_shape=(sequence_length, nb_features)))\n",
    "\n",
    "model.add(LSTM(\n",
    "         units=100,\n",
    "         return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(\n",
    "          units=50,\n",
    "          return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=nb_out))\n",
    "model.add(Activation(\"linear\"))\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop',metrics=['mae',r2_keras])\n",
    "# model.compile(loss=scoring_error, optimizer='rmsprop',metrics=['mae',r2_keras])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /Users/zhehaoyu/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n\nTrain on 38721 samples, validate on 2038 samples\nEpoch 1/100\n - 95s - loss: 5714.8156 - mean_absolute_error: 63.7078 - r2_keras: -2.1727e+00 - val_loss: 5832.1521 - val_mean_absolute_error: 64.5685 - val_r2_keras: -2.9435e+00\nEpoch 2/100\n - 85s - loss: 4603.6409 - mean_absolute_error: 56.3774 - r2_keras: -1.5515e+00 - val_loss: 4743.7854 - val_mean_absolute_error: 57.7878 - val_r2_keras: -2.1940e+00\nEpoch 3/100\n - 85s - loss: 3705.2192 - mean_absolute_error: 50.4575 - r2_keras: -1.0555e+00 - val_loss: 3839.6590 - val_mean_absolute_error: 52.0964 - val_r2_keras: -1.6085e+00\nEpoch 4/100\n - 89s - loss: 2983.2246 - mean_absolute_error: 45.6309 - r2_keras: -6.5317e-01 - val_loss: 3113.2973 - val_mean_absolute_error: 47.4518 - val_r2_keras: -1.1818e+00\nEpoch 5/100\n - 85s - loss: 2443.9740 - mean_absolute_error: 42.0124 - r2_keras: -3.5328e-01 - val_loss: 2560.1734 - val_mean_absolute_error: 43.8268 - val_r2_keras: -9.1120e-01\nEpoch 6/100\n - 86s - loss: 2078.7658 - mean_absolute_error: 39.4719 - r2_keras: -1.5096e-01 - val_loss: 2187.5504 - val_mean_absolute_error: 41.2732 - val_r2_keras: -7.9814e-01\nEpoch 7/100\n - 86s - loss: 1889.0196 - mean_absolute_error: 38.0730 - r2_keras: -4.4833e-02 - val_loss: 2001.7304 - val_mean_absolute_error: 39.8709 - val_r2_keras: -8.2051e-01\nEpoch 8/100\n - 87s - loss: 1852.0262 - mean_absolute_error: 37.7613 - r2_keras: -2.3799e-02 - val_loss: 1940.0233 - val_mean_absolute_error: 39.3059 - val_r2_keras: -7.5928e-01\nEpoch 9/100\n - 94s - loss: 1841.5022 - mean_absolute_error: 37.5373 - r2_keras: -1.8462e-02 - val_loss: 1729.6703 - val_mean_absolute_error: 37.0524 - val_r2_keras: -4.4437e-01\nEpoch 10/100\n - 95s - loss: 1627.2019 - mean_absolute_error: 34.7473 - r2_keras: 0.1005 - val_loss: 1701.5709 - val_mean_absolute_error: 36.2617 - val_r2_keras: -3.4179e-01\nEpoch 11/100\n - 91s - loss: 1292.1611 - mean_absolute_error: 30.4475 - r2_keras: 0.2851 - val_loss: 1718.1877 - val_mean_absolute_error: 35.9330 - val_r2_keras: -3.6149e-01\nEpoch 12/100\n - 87s - loss: 1150.9462 - mean_absolute_error: 28.4227 - r2_keras: 0.3630 - val_loss: 1450.5124 - val_mean_absolute_error: 33.2489 - val_r2_keras: -1.3392e-01\nEpoch 13/100\n - 86s - loss: 1055.5764 - mean_absolute_error: 26.8752 - r2_keras: 0.4151 - val_loss: 1630.2565 - val_mean_absolute_error: 33.7035 - val_r2_keras: -2.4562e-01\nEpoch 14/100\n - 87s - loss: 952.0671 - mean_absolute_error: 25.3140 - r2_keras: 0.4723 - val_loss: 1326.7300 - val_mean_absolute_error: 32.1051 - val_r2_keras: -1.3759e-01\nEpoch 15/100\n - 91s - loss: 884.7918 - mean_absolute_error: 24.2578 - r2_keras: 0.5099 - val_loss: 1243.3346 - val_mean_absolute_error: 29.8654 - val_r2_keras: -1.0114e-02\nEpoch 16/100\n - 89s - loss: 829.1665 - mean_absolute_error: 23.3288 - r2_keras: 0.5404 - val_loss: 1213.4649 - val_mean_absolute_error: 28.4114 - val_r2_keras: 0.0455\nEpoch 17/100\n - 86s - loss: 807.2339 - mean_absolute_error: 22.9182 - r2_keras: 0.5529 - val_loss: 1475.9704 - val_mean_absolute_error: 30.6130 - val_r2_keras: -1.5203e-01\nEpoch 18/100\n - 88s - loss: 776.7987 - mean_absolute_error: 22.3859 - r2_keras: 0.5694 - val_loss: 1045.7509 - val_mean_absolute_error: 27.2911 - val_r2_keras: 0.0854\nEpoch 19/100\n - 86s - loss: 760.6063 - mean_absolute_error: 22.0017 - r2_keras: 0.5784 - val_loss: 1031.2556 - val_mean_absolute_error: 26.4148 - val_r2_keras: 0.1850\nEpoch 20/100\n - 92s - loss: 752.1872 - mean_absolute_error: 22.0120 - r2_keras: 0.5819 - val_loss: 1004.0556 - val_mean_absolute_error: 25.7573 - val_r2_keras: 0.2250\nEpoch 21/100\n - 90s - loss: 725.4954 - mean_absolute_error: 21.5313 - r2_keras: 0.5974 - val_loss: 870.2834 - val_mean_absolute_error: 25.5483 - val_r2_keras: 0.3246\nEpoch 22/100\n - 94s - loss: 1039.1237 - mean_absolute_error: 25.5570 - r2_keras: 0.4253 - val_loss: 1744.8407 - val_mean_absolute_error: 35.3481 - val_r2_keras: -3.4798e-01\nEpoch 23/100\n - 90s - loss: 1112.7829 - mean_absolute_error: 27.3663 - r2_keras: 0.3832 - val_loss: 1034.8541 - val_mean_absolute_error: 27.6341 - val_r2_keras: 0.1774\nEpoch 24/100\n - 93s - loss: 731.5303 - mean_absolute_error: 21.8442 - r2_keras: 0.5944 - val_loss: 964.4563 - val_mean_absolute_error: 26.4005 - val_r2_keras: 0.1728\nEpoch 25/100\n - 91s - loss: 680.3728 - mean_absolute_error: 20.8656 - r2_keras: 0.6224 - val_loss: 868.5301 - val_mean_absolute_error: 24.9135 - val_r2_keras: 0.2528\nEpoch 26/100\n - 95s - loss: 657.2756 - mean_absolute_error: 20.4060 - r2_keras: 0.6352 - val_loss: 861.3127 - val_mean_absolute_error: 23.6280 - val_r2_keras: 0.3362\nEpoch 27/100\n - 98s - loss: 626.4635 - mean_absolute_error: 19.7739 - r2_keras: 0.6523 - val_loss: 761.9020 - val_mean_absolute_error: 22.7203 - val_r2_keras: 0.3757\nEpoch 28/100\n - 96s - loss: 611.4885 - mean_absolute_error: 19.5023 - r2_keras: 0.6609 - val_loss: 797.3160 - val_mean_absolute_error: 22.7407 - val_r2_keras: 0.3609\nEpoch 29/100\n - 92s - loss: 582.7936 - mean_absolute_error: 18.9576 - r2_keras: 0.6762 - val_loss: 1139.3046 - val_mean_absolute_error: 26.4938 - val_r2_keras: 0.1407\nEpoch 30/100\n - 89s - loss: 568.2782 - mean_absolute_error: 18.6536 - r2_keras: 0.6840 - val_loss: 781.7939 - val_mean_absolute_error: 22.8022 - val_r2_keras: 0.3637\nEpoch 31/100\n - 92s - loss: 542.6530 - mean_absolute_error: 18.2486 - r2_keras: 0.6984 - val_loss: 757.8357 - val_mean_absolute_error: 21.8255 - val_r2_keras: 0.3801\nEpoch 32/100\n - 89s - loss: 525.0826 - mean_absolute_error: 17.9108 - r2_keras: 0.7087 - val_loss: 636.9499 - val_mean_absolute_error: 20.7106 - val_r2_keras: 0.4308\nEpoch 33/100\n - 86s - loss: 496.5060 - mean_absolute_error: 17.3765 - r2_keras: 0.7236 - val_loss: 776.3776 - val_mean_absolute_error: 22.1234 - val_r2_keras: 0.3764\nEpoch 34/100\n - 86s - loss: 471.7973 - mean_absolute_error: 16.8943 - r2_keras: 0.7384 - val_loss: 575.9556 - val_mean_absolute_error: 19.0736 - val_r2_keras: 0.4850\nEpoch 35/100\n - 92s - loss: 454.7838 - mean_absolute_error: 16.5777 - r2_keras: 0.7477 - val_loss: 633.3921 - val_mean_absolute_error: 20.4007 - val_r2_keras: 0.5073\nEpoch 36/100\n - 87s - loss: 442.7713 - mean_absolute_error: 16.3767 - r2_keras: 0.7541 - val_loss: 632.6125 - val_mean_absolute_error: 19.8707 - val_r2_keras: 0.5299\nEpoch 37/100\n - 85s - loss: 414.4734 - mean_absolute_error: 15.7643 - r2_keras: 0.7698 - val_loss: 678.0137 - val_mean_absolute_error: 20.3736 - val_r2_keras: 0.4350\nEpoch 38/100\n - 91s - loss: 399.8316 - mean_absolute_error: 15.4728 - r2_keras: 0.7774 - val_loss: 558.2630 - val_mean_absolute_error: 18.6447 - val_r2_keras: 0.5530\nEpoch 39/100\n - 92s - loss: 381.5211 - mean_absolute_error: 15.0805 - r2_keras: 0.7883 - val_loss: 373.4398 - val_mean_absolute_error: 15.4615 - val_r2_keras: 0.6902\nEpoch 40/100\n - 93s - loss: 370.8848 - mean_absolute_error: 14.8494 - r2_keras: 0.7941 - val_loss: 556.6974 - val_mean_absolute_error: 18.7580 - val_r2_keras: 0.5415\nEpoch 41/100\n - 91s - loss: 352.1044 - mean_absolute_error: 14.3809 - r2_keras: 0.8044 - val_loss: 624.8893 - val_mean_absolute_error: 18.7203 - val_r2_keras: 0.4359\nEpoch 42/100\n - 90s - loss: 343.5830 - mean_absolute_error: 14.2106 - r2_keras: 0.8094 - val_loss: 960.4060 - val_mean_absolute_error: 23.8081 - val_r2_keras: 0.1539\nEpoch 43/100\n - 94s - loss: 336.8646 - mean_absolute_error: 13.9946 - r2_keras: 0.8130 - val_loss: 507.2598 - val_mean_absolute_error: 17.8427 - val_r2_keras: 0.5706\nEpoch 44/100\n - 95s - loss: 318.4734 - mean_absolute_error: 13.5962 - r2_keras: 0.8233 - val_loss: 370.5031 - val_mean_absolute_error: 15.4983 - val_r2_keras: 0.6874\nEpoch 45/100\n - 95s - loss: 305.9290 - mean_absolute_error: 13.3496 - r2_keras: 0.8300 - val_loss: 387.7196 - val_mean_absolute_error: 15.3759 - val_r2_keras: 0.6680\nEpoch 46/100\n - 90s - loss: 298.3968 - mean_absolute_error: 13.1357 - r2_keras: 0.8344 - val_loss: 387.0955 - val_mean_absolute_error: 15.0093 - val_r2_keras: 0.6646\nEpoch 47/100\n - 91s - loss: 283.5720 - mean_absolute_error: 12.7868 - r2_keras: 0.8424 - val_loss: 396.2038 - val_mean_absolute_error: 15.1338 - val_r2_keras: 0.6947\nEpoch 48/100\n - 92s - loss: 275.3816 - mean_absolute_error: 12.5940 - r2_keras: 0.8471 - val_loss: 337.2477 - val_mean_absolute_error: 13.9973 - val_r2_keras: 0.7281\nEpoch 49/100\n - 92s - loss: 262.6941 - mean_absolute_error: 12.2923 - r2_keras: 0.8541 - val_loss: 358.4669 - val_mean_absolute_error: 14.5756 - val_r2_keras: 0.6987\nEpoch 50/100\n - 91s - loss: 246.7347 - mean_absolute_error: 11.9204 - r2_keras: 0.8631 - val_loss: 317.2268 - val_mean_absolute_error: 13.7959 - val_r2_keras: 0.7409\nEpoch 51/100\n - 92s - loss: 244.3772 - mean_absolute_error: 11.7919 - r2_keras: 0.8643 - val_loss: 372.7519 - val_mean_absolute_error: 14.9799 - val_r2_keras: 0.7009\nEpoch 52/100\n - 88s - loss: 229.4906 - mean_absolute_error: 11.4688 - r2_keras: 0.8727 - val_loss: 528.9863 - val_mean_absolute_error: 17.0634 - val_r2_keras: 0.5862\nEpoch 53/100\n - 86s - loss: 222.2174 - mean_absolute_error: 11.3028 - r2_keras: 0.8764 - val_loss: 448.6405 - val_mean_absolute_error: 15.5083 - val_r2_keras: 0.6351\nEpoch 54/100\n - 87s - loss: 209.7233 - mean_absolute_error: 10.9425 - r2_keras: 0.8836 - val_loss: 658.0619 - val_mean_absolute_error: 19.1420 - val_r2_keras: 0.4541\nEpoch 55/100\n - 94s - loss: 206.7999 - mean_absolute_error: 10.8782 - r2_keras: 0.8855 - val_loss: 439.4229 - val_mean_absolute_error: 17.8085 - val_r2_keras: 0.6260\nEpoch 56/100\n - 93s - loss: 190.2120 - mean_absolute_error: 10.4567 - r2_keras: 0.8945 - val_loss: 802.6077 - val_mean_absolute_error: 21.1359 - val_r2_keras: 0.3537\nEpoch 57/100\n - 93s - loss: 186.8765 - mean_absolute_error: 10.3572 - r2_keras: 0.8961 - val_loss: 433.9749 - val_mean_absolute_error: 15.8099 - val_r2_keras: 0.6698\nEpoch 58/100\n - 91s - loss: 175.4921 - mean_absolute_error: 10.0167 - r2_keras: 0.9024 - val_loss: 366.1740 - val_mean_absolute_error: 14.0328 - val_r2_keras: 0.6886\nEpoch 59/100\n - 94s - loss: 167.8977 - mean_absolute_error: 9.7913 - r2_keras: 0.9067 - val_loss: 399.2258 - val_mean_absolute_error: 15.6795 - val_r2_keras: 0.6862\nEpoch 60/100\n - 93s - loss: 160.2843 - mean_absolute_error: 9.6238 - r2_keras: 0.9111 - val_loss: 456.1308 - val_mean_absolute_error: 15.7672 - val_r2_keras: 0.5972\ndict_keys(['val_loss', 'val_mean_absolute_error', 'val_r2_keras', 'loss', 'mean_absolute_error', 'r2_keras'])\n"
    }
   ],
   "source": [
    "# fit the network\n",
    "model_path='use_mask.h5'\n",
    "history = model.fit(seq_array, label_array, epochs=100, batch_size=200, validation_split=0.05, verbose=2,\n",
    "          callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min'),\n",
    "                       keras.callbacks.ModelCheckpoint(model_path,monitor='val_loss', save_best_only=True, mode='min', verbose=0)]\n",
    "          )\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "40759/40759 [==============================] - 34s 837us/step\nLoss: 144.06500492195622\n"
    }
   ],
   "source": [
    "# training metrics\n",
    "scores = model.evaluate(seq_array, label_array, verbose=1, batch_size=200)\n",
    "print('Loss: {}'.format(scores[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use padding in test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        id  cycle  setting1  setting2  setting3        s1        s2        s3  \\\n0        1      1  0.238019  0.297150       1.0  0.597937  0.639243  0.691329   \n1        1      2  0.476162  0.831354       1.0  0.626985  0.664861  0.647519   \n2        1      3  0.833282  0.997625       1.0  0.060269  0.189055  0.312512   \n3        1      4  0.999967  0.998812       1.0  0.000000  0.135525  0.286753   \n4        1      5  0.595089  0.737886       0.0  0.238089  0.012028  0.022001   \n...    ...    ...       ...       ...       ...       ...       ...       ...   \n33986  259    119  0.833210  0.997981       1.0  0.060269  0.185015  0.331523   \n33987  259    120  0.999967  0.998219       1.0  0.000000  0.128638  0.290703   \n33988  259    121  0.999955  0.997625       1.0  0.000000  0.130750  0.285244   \n33989  259    122  0.000057  0.000356       1.0  1.000000  0.984024  0.944915   \n33990  259    123  0.999888  0.997625       1.0  0.000000  0.131852  0.267029   \n\n             s4        s5  ...  s19       s20       s21  mode1  mode2  mode3  \\\n0      0.680395  0.617180  ...  1.0  0.625944  0.630724    0.0    0.0    0.0   \n1      0.534663  0.507937  ...  1.0  0.484214  0.496301    0.0    0.0    0.0   \n2      0.243225  0.146592  ...  1.0  0.164722  0.159476    0.0    1.0    0.0   \n3      0.242061  0.000000  ...  1.0  0.005834  0.016866    0.0    0.0    0.0   \n4      0.050986  0.293184  ...  0.0  0.141730  0.140123    1.0    0.0    0.0   \n...         ...       ...  ...  ...       ...       ...    ...    ...    ...   \n33986  0.245972  0.146592  ...  1.0  0.163349  0.159133    0.0    1.0    0.0   \n33987  0.232087  0.000000  ...  1.0  0.013384  0.016260    0.0    0.0    0.0   \n33988  0.219835  0.000000  ...  1.0  0.013384  0.020433    0.0    0.0    0.0   \n33989  0.935747  1.000000  ...  1.0  0.991764  0.985410    0.0    0.0    1.0   \n33990  0.239759  0.000000  ...  1.0  0.015443  0.012858    0.0    0.0    0.0   \n\n       mode4  mode5  mode6  cycle_norm  \n0        0.0    1.0    0.0    0.000000  \n1        1.0    0.0    0.0    0.002732  \n2        0.0    0.0    0.0    0.005464  \n3        0.0    0.0    1.0    0.008197  \n4        0.0    0.0    0.0    0.010929  \n...      ...    ...    ...         ...  \n33986    0.0    0.0    0.0    0.322404  \n33987    0.0    0.0    1.0    0.325137  \n33988    0.0    0.0    1.0    0.327869  \n33989    0.0    0.0    0.0    0.330601  \n33990    0.0    0.0    1.0    0.333333  \n\n[33991 rows x 33 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cycle</th>\n      <th>setting1</th>\n      <th>setting2</th>\n      <th>setting3</th>\n      <th>s1</th>\n      <th>s2</th>\n      <th>s3</th>\n      <th>s4</th>\n      <th>s5</th>\n      <th>...</th>\n      <th>s19</th>\n      <th>s20</th>\n      <th>s21</th>\n      <th>mode1</th>\n      <th>mode2</th>\n      <th>mode3</th>\n      <th>mode4</th>\n      <th>mode5</th>\n      <th>mode6</th>\n      <th>cycle_norm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.238019</td>\n      <td>0.297150</td>\n      <td>1.0</td>\n      <td>0.597937</td>\n      <td>0.639243</td>\n      <td>0.691329</td>\n      <td>0.680395</td>\n      <td>0.617180</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.625944</td>\n      <td>0.630724</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.476162</td>\n      <td>0.831354</td>\n      <td>1.0</td>\n      <td>0.626985</td>\n      <td>0.664861</td>\n      <td>0.647519</td>\n      <td>0.534663</td>\n      <td>0.507937</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.484214</td>\n      <td>0.496301</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.002732</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0.833282</td>\n      <td>0.997625</td>\n      <td>1.0</td>\n      <td>0.060269</td>\n      <td>0.189055</td>\n      <td>0.312512</td>\n      <td>0.243225</td>\n      <td>0.146592</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.164722</td>\n      <td>0.159476</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.005464</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.999967</td>\n      <td>0.998812</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.135525</td>\n      <td>0.286753</td>\n      <td>0.242061</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.005834</td>\n      <td>0.016866</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.008197</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>0.595089</td>\n      <td>0.737886</td>\n      <td>0.0</td>\n      <td>0.238089</td>\n      <td>0.012028</td>\n      <td>0.022001</td>\n      <td>0.050986</td>\n      <td>0.293184</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.141730</td>\n      <td>0.140123</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.010929</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33986</th>\n      <td>259</td>\n      <td>119</td>\n      <td>0.833210</td>\n      <td>0.997981</td>\n      <td>1.0</td>\n      <td>0.060269</td>\n      <td>0.185015</td>\n      <td>0.331523</td>\n      <td>0.245972</td>\n      <td>0.146592</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.163349</td>\n      <td>0.159133</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.322404</td>\n    </tr>\n    <tr>\n      <th>33987</th>\n      <td>259</td>\n      <td>120</td>\n      <td>0.999967</td>\n      <td>0.998219</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.128638</td>\n      <td>0.290703</td>\n      <td>0.232087</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.013384</td>\n      <td>0.016260</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.325137</td>\n    </tr>\n    <tr>\n      <th>33988</th>\n      <td>259</td>\n      <td>121</td>\n      <td>0.999955</td>\n      <td>0.997625</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.130750</td>\n      <td>0.285244</td>\n      <td>0.219835</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.013384</td>\n      <td>0.020433</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.327869</td>\n    </tr>\n    <tr>\n      <th>33989</th>\n      <td>259</td>\n      <td>122</td>\n      <td>0.000057</td>\n      <td>0.000356</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>0.984024</td>\n      <td>0.944915</td>\n      <td>0.935747</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.991764</td>\n      <td>0.985410</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.330601</td>\n    </tr>\n    <tr>\n      <th>33990</th>\n      <td>259</td>\n      <td>123</td>\n      <td>0.999888</td>\n      <td>0.997625</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.131852</td>\n      <td>0.267029</td>\n      <td>0.239759</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.015443</td>\n      <td>0.012858</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n    </tr>\n  </tbody>\n</table>\n<p>33991 rows × 33 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "259"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "len(td.groupby('id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pick the last sequence for each id in the test data\n",
    "test = [td[td['id']==id][sequence_cols].values[-sequence_length:] \n",
    "                       for id in td['id'].unique() if len(td[td['id']==id]) >= sequence_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "235"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for i in range(len(td.groupby('id'))):\n",
    "    if len(td[td['id']==(i+1)]) >= sequence_length:\n",
    "        test.append(np.asarray(td[td['id']==(i+1)][sequence_cols].values[-sequence_length:]).astype(np.float32).tolist())\n",
    "    else:\n",
    "        test.append(np.asarray(td[td['id']==(i+1)][sequence_cols].values[:]).astype(np.float32).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_inputs = keras.preprocessing.sequence.pad_sequences(test,dtype='float32',                                padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "259/259 [==============================] - 1s 2ms/step\n"
    }
   ],
   "source": [
    "result = model.predict(padded_inputs,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_excel('../results_submission.xls')\n",
    "submit['RUL prediction']=result\n",
    "submit.to_csv('use_mask.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(259,)"
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "ans = np.loadtxt('../RUL_FD002.txt')\n",
    "ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(user_ans):\n",
    "    user_ans_arr = np.array(user_ans)\n",
    "    score = 0\n",
    "    diff = user_ans_arr - ans\n",
    "    diff_pos = diff[diff>=0]\n",
    "    diff_neg = diff[diff<0]\n",
    "    score = np.sum((np.exp(-1./13.*diff_neg)-1))+np.sum((np.exp(1./10.*diff_pos)-1))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = pd.read_csv('./use_mask.csv')\n",
    "pred_rul=re['RUL prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "7642.120277261509"
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "score(pred_rul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}